{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rforest\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "from sklearn import tree\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import Image as display\n",
    "import graphviz \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.)\n",
    "Start with an image of the Mona Lisa. If you don’t like the Mona Lisa, pick another interesting\n",
    "image of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 604, 3)\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"mona_lisa.jpg\")\n",
    "pix = np.array(im.getdata(),dtype=np.uint8)\n",
    "w, h = im.size\n",
    "pix.shape = (h, w, len(pix[0]))\n",
    "print(pix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.)\n",
    "To build your “training set,” uniformly sample 5,000 random (x, y)\n",
    "coordinate locations.\n",
    "\n",
    "Done\n",
    "\n",
    "What other preprocessing steps are necessary for random forests inputs? Describe them,\n",
    "implement them, and justify your decisions. In particular, do you need to perform mean\n",
    "subtraction, standardization, or unit-normalization?\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[542, 211],\n",
       "       [430, 441],\n",
       "       [190, 374],\n",
       "       ..., \n",
       "       [ 89, 433],\n",
       "       [849, 271],\n",
       "       [546, 569]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleset = []\n",
    "samplecoords = []\n",
    "for sample in range(5000):\n",
    "    row = np.random.randint(0, h-1)\n",
    "    col = np.random.randint(0, w-1)\n",
    "    newcoords = [row, col] \n",
    "    sampleset.append(pix[row,col])\n",
    "    samplecoords.append(newcoords)\n",
    "np.asarray(sampleset)\n",
    "np.asarray(samplecoords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img = Image.fromarray(pix, 'RGB')\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.)\n",
    "Sample pixel values at each of the given coordinate locations.\n",
    "Each pixel contains red, green, and blue intensity values, so decide how you want to handle\n",
    "this.\n",
    "\n",
    "I chose to regress all three values at once. I.e., Function maps (x, y) coordinates to (r, g , b) values.\n",
    "\n",
    "What other preprocessing steps are necessary for random regression forest outputs? Describe\n",
    "them, implement them, and justify your decisions.\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.)\n",
    "\n",
    "To build the final image, for each pixel of the output, feed the pixel coordinate through the\n",
    "random forest and color the resulting pixel with the output prediction. You can then use\n",
    "imshow to view the result. (If you are using grayscale, try imshow(Y, cmap=’gray’) to avoid\n",
    "fake-coloring).\n",
    "\n",
    "Implementation Used: sklearn.ensemble.RandomForestRegressor <br>\n",
    "CITE: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = rforest(max_depth=7, random_state=0)\n",
    "regr.fit(samplecoords, sampleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newpix = np.zeros(shape=(h,w,3))\n",
    "# for row in range(h):\n",
    "#     for col in range(w):\n",
    "#         newpix[row,col] = regr.predict(np.array([row,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testcoords = []\n",
    "for row in range(h):\n",
    "    for col in range(w):\n",
    "        testcoords.append([row, col])\n",
    "testcoords = np.asarray(testcoords)\n",
    "out = regr.predict(testcoords)\n",
    "out.shape = (h, w, 3)\n",
    "out = out.astype(np.uint8)\n",
    "img = Image.fromarray(out, 'RGB')\n",
    "img.save(\"depth_7_10_trees.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"depth_7_10_trees.jpg\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.) Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.)\n",
    "Repeat the experiment for a random forest containing a single decision tree, but with\n",
    "depths 1, 2, 3, 5, 10, and 15. How does depth impact the result? Describe in detail why.\n",
    "\n",
    "With increased depth, the number of rectangles increases. The resulting image has a more granular and accurate appearance. The reason for this is that by increasing the number of layers, we have increased the number of split points that model the painting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for depth in [1, 2, 3, 5, 10, 15]:\n",
    "    regr = rforest(n_estimators = 1, max_depth=depth, random_state=0)\n",
    "    regr.fit(samplecoords, sampleset)\n",
    "    testcoords = []\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            testcoords.append([row, col])\n",
    "    testcoords = np.asarray(testcoords)\n",
    "    out = regr.predict(testcoords)\n",
    "    out.shape = (h, w, 3)\n",
    "    out = out.astype(np.uint8)\n",
    "    img = Image.fromarray(out, 'RGB')\n",
    "    img.save(\"depth_\"+str(depth)+\"_1_tree.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"depth_1_1_tree.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_2_1_tree.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_3_1_tree.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_5_1_tree.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_10_1_tree.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_15_1_tree.jpg\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.)\n",
    "Repeat the experiment for a random forest of depth 7, but with number of trees equal to\n",
    "1, 3, 5, 10, and 100. How does the number of trees impact the result? Describe in detail\n",
    "why.\n",
    "\n",
    "Increasing the number of trees in the forest makes the resulting image appear more smooth. The colors are more blended. The reason for this is that the pixel colors are now chosen as a majority vote among the leaves in the trees of the forests, and not all forests are trained on the same subsample of the training set. As such, increasing the number of trees in the forest increases the color accuracy at a given point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for estimators in [1, 3, 5, 10, 100]:\n",
    "    regr = rforest(n_estimators = estimators, max_depth=7, random_state=0)\n",
    "    regr.fit(samplecoords, sampleset)\n",
    "    testcoords = []\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            testcoords.append([row, col])\n",
    "    testcoords = np.asarray(testcoords)\n",
    "    out = regr.predict(testcoords)\n",
    "    out.shape = (h, w, 3)\n",
    "    out = out.astype(np.uint8)\n",
    "    img = Image.fromarray(out, 'RGB')\n",
    "    img.save(\"depth_7_\"+str(estimators)+\"_trees.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"depth_7_1_trees.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_7_3_trees.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_7_5_trees.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_7_10_trees.jpg\" style=\"width: 200px;\"/>\n",
    "<img src=\"depth_7_100_trees.jpg\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.)\n",
    "As a simple baseline, repeat the experiment using a k-NN regressor, for k = 1. This means\n",
    "that every pixel in the output will equal the nearest pixel from the “training set.” Compare\n",
    "and contrast the outlook: why does this look the way it does?\n",
    "\n",
    "The resulting image looks comparable to the high-depth tree regression, but better resembles the Mona Lisa. The reason for this is that the pixel regions are more circular (rather than rectangular), which better supports the way that the human eye processes images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neigh = knn(n_neighbors=1)\n",
    "neigh.fit(samplecoords, sampleset) \n",
    "testcoords = []\n",
    "for row in range(h):\n",
    "    for col in range(w):\n",
    "        testcoords.append([row, col])\n",
    "testcoords = np.asarray(testcoords)\n",
    "out = neigh.predict(testcoords)\n",
    "out.shape = (h, w, 3)\n",
    "out = out.astype(np.uint8)\n",
    "img = Image.fromarray(out, 'RGB')\n",
    "img.save(\"knn_k_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"knn_k_1.jpg\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv.) \n",
    "Experiment with different pruning strategies of your choice. <br>\n",
    "From Wikipedia <https://en.wikipedia.org/wiki/Pruning_(decision_trees)>\n",
    "<img src=\"pruning_methods.png\"/>\n",
    "\n",
    "We attempted a form of reduced error pruning. We proceeded by doing a depth-first traversal of the graph. For each node traversed, we evaluate the score of the decision tree if the subgraph starting at the current node is pruned. If the score improves, we prune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = rforest(n_estimators = 1, max_depth=7, random_state=0)\n",
    "regr.fit(samplecoords, sampleset)\n",
    "rtree = regr.estimators_[0].tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   1],\n",
       "       [  0,   2],\n",
       "       ..., \n",
       "       [899, 601],\n",
       "       [899, 602],\n",
       "       [899, 603]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = []\n",
    "testcoords = []\n",
    "for row in range(h):\n",
    "    for col in range(w):\n",
    "        newcoords = [row, col] \n",
    "        testset.append(pix[row,col])\n",
    "        testcoords.append(newcoords)\n",
    "np.asarray(testset)\n",
    "np.asarray(testcoords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = regr.predict(testcoords)\n",
    "out.shape = (h, w, 3)\n",
    "out = out.astype(np.uint8)\n",
    "img = Image.fromarray(out, 'RGB')\n",
    "img.save(\"pre-prune_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'monalisa.pdf'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(rtree, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"monalisa\", view=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returns feature and indices of left and right children\n",
    "def children(tree, index):\n",
    "    root = tree.feature[index]\n",
    "    left_index = tree.children_left[index]\n",
    "    right_index = tree.children_right[index]\n",
    "    if(right_index > index and left_index > index):\n",
    "        return (left_index, right_index)\n",
    "    else:\n",
    "        return None\n",
    "pruneint = children(rtree, 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prune.pdf'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subtree_nodes(tree, index, removal):\n",
    "    removal.append(index)\n",
    "    nodechildren = children(tree, index)\n",
    "    if(nodechildren != None):\n",
    "        get_subtree_nodes(tree, nodechildren[0], removal)\n",
    "        get_subtree_nodes(tree, nodechildren[1], removal)\n",
    "    return removal\n",
    "\n",
    "def prune_subtree(tree, index):\n",
    "    new_tree = deepcopy(tree)\n",
    "    removal = get_subtree_nodes(new_tree, index, [])\n",
    "    newval = new_tree.value[index]\n",
    "    for i in removal:\n",
    "        new_tree.children_left[i] = -1\n",
    "        new_tree.children_right[i] = -1\n",
    "        new_tree.value[i] = newval\n",
    "#     new_tree.node_count -= len(removal)\n",
    "#     new_tree.node_count += 1\n",
    "    return new_tree\n",
    "\n",
    "new_tree = prune_subtree(rtree, pruneint)\n",
    "dot_data = tree.export_graphviz(new_tree, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"prune\", view=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139878324665\n"
     ]
    }
   ],
   "source": [
    "regr2 = rforest(n_estimators = 1, max_depth=7, random_state=0)\n",
    "regr2.fit(samplecoords, sampleset)\n",
    "regr2.estimators_[0].tree_ = new_tree\n",
    "print(regr.score(testcoords, testset) - regr2.score(testcoords, testset))\n",
    "out = regr2.predict(testcoords)\n",
    "out.shape = (h, w, 3)\n",
    "out = out.astype(np.uint8)\n",
    "img = Image.fromarray(out, 'RGB')\n",
    "img.save(\"prune_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduced_error_pruning(regressor, startindex, testcoords, testset):\n",
    "    print(\"PRUNE:\", startindex)\n",
    "    current_score = regressor.score(testcoords, testset)\n",
    "    regrtree = regressor.estimators_[0].tree_\n",
    "    nodechildren = children(regrtree, startindex)\n",
    "    newregr = deepcopy(regressor)\n",
    "    if(nodechildren != None):\n",
    "        left_tree = prune_subtree(regrtree, nodechildren[0])\n",
    "        right_tree = prune_subtree(regrtree, nodechildren[1])\n",
    "        joint_tree = prune_subtree(left_tree, nodechildren[1])\n",
    "        print(\"SCORING\")\n",
    "        newregr.estimators_[0].tree_ = left_tree\n",
    "        left_score = newregr.score(testcoords, testset)\n",
    "        newregr.estimators_[0].tree_ = right_tree\n",
    "        right_score = newregr.score(testcoords, testset)\n",
    "        if(left_score > current_score and right_score > current_score):\n",
    "            print(\"PRUNING LEFT AND RIGHT CHILDREN OF\", startindex)\n",
    "            regressor.estimators_[0].tree_ = joint_tree\n",
    "        elif(left_score > current_score):\n",
    "            print(\"PRUNING LEFT CHILDREN OF\", startindex)\n",
    "            regressor.estimators_[0].tree_ = left_tree\n",
    "            reduced_error_pruning(regressor, nodechildren[1], testcoords, testset)\n",
    "        elif(right_score > current_score):\n",
    "            print(\"PRUNING RIGHT CHILDREN OF\", startindex)\n",
    "            regressor.estimators_[0].tree_ = right_tree\n",
    "            reduced_error_pruning(regressor, nodechildren[0], testcoords, testset)\n",
    "        else:\n",
    "            print(\"NO ERROR REDUCTION\", startindex)\n",
    "            reduced_error_pruning(regressor, nodechildren[0], testcoords, testset)\n",
    "            reduced_error_pruning(regressor, nodechildren[1], testcoords, testset)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUNE: 0\n",
      "NO ERROR REDUCTION 0\n",
      "PRUNE: 1\n",
      "NO ERROR REDUCTION 1\n",
      "PRUNE: 2\n",
      "NO ERROR REDUCTION 2\n",
      "PRUNE: 3\n",
      "PRUNING LEFT CHILDREN OF 3\n",
      "PRUNE: 19\n",
      "PRUNING RIGHT CHILDREN OF 19\n",
      "PRUNE: 20\n",
      "NO ERROR REDUCTION 20\n",
      "PRUNE: 21\n",
      "NO ERROR REDUCTION 21\n",
      "PRUNE: 22\n",
      "PRUNE: 23\n",
      "PRUNE: 24\n",
      "PRUNE: 30\n",
      "NO ERROR REDUCTION 30\n",
      "PRUNE: 31\n",
      "NO ERROR REDUCTION 31\n",
      "PRUNE: 32\n",
      "NO ERROR REDUCTION 32\n",
      "PRUNE: 33\n",
      "NO ERROR REDUCTION 33\n",
      "PRUNE: 34\n",
      "PRUNE: 35\n",
      "PRUNE: 36\n",
      "NO ERROR REDUCTION 36\n",
      "PRUNE: 37\n",
      "PRUNE: 38\n",
      "PRUNE: 39\n",
      "NO ERROR REDUCTION 39\n",
      "PRUNE: 40\n",
      "NO ERROR REDUCTION 40\n",
      "PRUNE: 41\n",
      "PRUNE: 42\n",
      "PRUNE: 43\n",
      "NO ERROR REDUCTION 43\n",
      "PRUNE: 44\n",
      "PRUNE: 45\n",
      "PRUNE: 46\n",
      "NO ERROR REDUCTION 46\n",
      "PRUNE: 47\n",
      "PRUNING LEFT CHILDREN OF 47\n",
      "PRUNE: 51\n",
      "NO ERROR REDUCTION 51\n",
      "PRUNE: 52\n",
      "PRUNE: 53\n",
      "PRUNE: 54\n",
      "NO ERROR REDUCTION 54\n",
      "PRUNE: 55\n",
      "NO ERROR REDUCTION 55\n",
      "PRUNE: 56\n",
      "PRUNE: 57\n",
      "PRUNE: 58\n",
      "NO ERROR REDUCTION 58\n",
      "PRUNE: 59\n",
      "PRUNE: 60\n",
      "PRUNE: 61\n",
      "NO ERROR REDUCTION 61\n",
      "PRUNE: 62\n",
      "NO ERROR REDUCTION 62\n",
      "PRUNE: 63\n",
      "NO ERROR REDUCTION 63\n",
      "PRUNE: 64\n",
      "NO ERROR REDUCTION 64\n",
      "PRUNE: 65\n",
      "NO ERROR REDUCTION 65\n",
      "PRUNE: 66\n",
      "PRUNE: 67\n",
      "PRUNE: 68\n",
      "NO ERROR REDUCTION 68\n",
      "PRUNE: 69\n",
      "PRUNE: 70\n",
      "PRUNE: 71\n",
      "NO ERROR REDUCTION 71\n",
      "PRUNE: 72\n",
      "NO ERROR REDUCTION 72\n",
      "PRUNE: 73\n",
      "PRUNE: 74\n",
      "PRUNE: 75\n",
      "NO ERROR REDUCTION 75\n",
      "PRUNE: 76\n",
      "PRUNE: 77\n",
      "PRUNE: 78\n",
      "NO ERROR REDUCTION 78\n",
      "PRUNE: 79\n",
      "NO ERROR REDUCTION 79\n",
      "PRUNE: 80\n",
      "NO ERROR REDUCTION 80\n",
      "PRUNE: 81\n",
      "PRUNE: 82\n",
      "PRUNE: 83\n",
      "NO ERROR REDUCTION 83\n",
      "PRUNE: 84\n",
      "PRUNE: 85\n",
      "PRUNE: 86\n",
      "PRUNING LEFT AND RIGHT CHILDREN OF 86\n",
      "PRUNE: 93\n",
      "NO ERROR REDUCTION 93\n",
      "PRUNE: 94\n",
      "NO ERROR REDUCTION 94\n",
      "PRUNE: 95\n",
      "NO ERROR REDUCTION 95\n",
      "PRUNE: 96\n",
      "NO ERROR REDUCTION 96\n",
      "PRUNE: 97\n",
      "PRUNE: 98\n",
      "PRUNE: 99\n",
      "NO ERROR REDUCTION 99\n",
      "PRUNE: 100\n",
      "PRUNE: 101\n",
      "PRUNE: 102\n",
      "NO ERROR REDUCTION 102\n",
      "PRUNE: 103\n",
      "NO ERROR REDUCTION 103\n",
      "PRUNE: 104\n",
      "PRUNE: 105\n",
      "PRUNE: 106\n",
      "NO ERROR REDUCTION 106\n",
      "PRUNE: 107\n",
      "PRUNE: 108\n",
      "PRUNE: 109\n",
      "NO ERROR REDUCTION 109\n",
      "PRUNE: 110\n",
      "NO ERROR REDUCTION 110\n",
      "PRUNE: 111\n",
      "NO ERROR REDUCTION 111\n",
      "PRUNE: 112\n",
      "PRUNE: 113\n",
      "PRUNE: 114\n",
      "NO ERROR REDUCTION 114\n",
      "PRUNE: 115\n",
      "PRUNE: 116\n",
      "PRUNE: 117\n",
      "NO ERROR REDUCTION 117\n",
      "PRUNE: 118\n",
      "NO ERROR REDUCTION 118\n",
      "PRUNE: 119\n",
      "PRUNE: 120\n",
      "PRUNE: 121\n",
      "NO ERROR REDUCTION 121\n",
      "PRUNE: 122\n",
      "PRUNE: 123\n",
      "PRUNE: 124\n",
      "NO ERROR REDUCTION 124\n",
      "PRUNE: 125\n",
      "NO ERROR REDUCTION 125\n",
      "PRUNE: 126\n",
      "NO ERROR REDUCTION 126\n",
      "PRUNE: 127\n",
      "NO ERROR REDUCTION 127\n",
      "PRUNE: 128\n",
      "NO ERROR REDUCTION 128\n",
      "PRUNE: 129\n",
      "NO ERROR REDUCTION 129\n",
      "PRUNE: 130\n",
      "PRUNE: 131\n",
      "PRUNE: 132\n",
      "NO ERROR REDUCTION 132\n",
      "PRUNE: 133\n",
      "PRUNE: 134\n",
      "PRUNE: 135\n",
      "PRUNING LEFT CHILDREN OF 135\n",
      "PRUNE: 139\n",
      "NO ERROR REDUCTION 139\n",
      "PRUNE: 140\n",
      "PRUNE: 141\n",
      "PRUNE: 142\n",
      "NO ERROR REDUCTION 142\n",
      "PRUNE: 143\n",
      "NO ERROR REDUCTION 143\n",
      "PRUNE: 144\n",
      "NO ERROR REDUCTION 144\n",
      "PRUNE: 145\n",
      "PRUNE: 146\n",
      "PRUNE: 147\n",
      "NO ERROR REDUCTION 147\n",
      "PRUNE: 148\n",
      "PRUNE: 149\n",
      "PRUNE: 150\n",
      "NO ERROR REDUCTION 150\n",
      "PRUNE: 151\n",
      "NO ERROR REDUCTION 151\n",
      "PRUNE: 152\n",
      "PRUNE: 153\n",
      "PRUNE: 154\n",
      "NO ERROR REDUCTION 154\n",
      "PRUNE: 155\n",
      "PRUNE: 156\n",
      "PRUNE: 157\n",
      "NO ERROR REDUCTION 157\n",
      "PRUNE: 158\n",
      "NO ERROR REDUCTION 158\n",
      "PRUNE: 159\n",
      "PRUNING RIGHT CHILDREN OF 159\n",
      "PRUNE: 160\n",
      "NO ERROR REDUCTION 160\n",
      "PRUNE: 161\n",
      "PRUNE: 162\n",
      "PRUNE: 166\n",
      "NO ERROR REDUCTION 166\n",
      "PRUNE: 167\n",
      "NO ERROR REDUCTION 167\n",
      "PRUNE: 168\n",
      "PRUNE: 169\n",
      "PRUNE: 170\n",
      "NO ERROR REDUCTION 170\n",
      "PRUNE: 171\n",
      "PRUNE: 172\n",
      "PRUNE: 173\n",
      "NO ERROR REDUCTION 173\n",
      "PRUNE: 174\n",
      "NO ERROR REDUCTION 174\n",
      "PRUNE: 175\n",
      "NO ERROR REDUCTION 175\n",
      "PRUNE: 176\n",
      "PRUNE: 177\n",
      "PRUNE: 178\n",
      "NO ERROR REDUCTION 178\n",
      "PRUNE: 179\n",
      "PRUNE: 180\n",
      "PRUNE: 181\n",
      "PRUNING LEFT AND RIGHT CHILDREN OF 181\n",
      "PRUNE: 188\n",
      "NO ERROR REDUCTION 188\n",
      "PRUNE: 189\n",
      "NO ERROR REDUCTION 189\n",
      "PRUNE: 190\n",
      "PRUNING LEFT CHILDREN OF 190\n",
      "PRUNE: 198\n",
      "NO ERROR REDUCTION 198\n",
      "PRUNE: 199\n",
      "NO ERROR REDUCTION 199\n",
      "PRUNE: 200\n",
      "PRUNE: 201\n",
      "PRUNE: 202\n",
      "NO ERROR REDUCTION 202\n",
      "PRUNE: 203\n",
      "PRUNE: 204\n",
      "PRUNE: 205\n",
      "PRUNING RIGHT CHILDREN OF 205\n",
      "PRUNE: 206\n",
      "PRUNING RIGHT CHILDREN OF 206\n",
      "PRUNE: 207\n",
      "NO ERROR REDUCTION 207\n",
      "PRUNE: 208\n",
      "PRUNE: 209\n",
      "PRUNE: 220\n",
      "PRUNING LEFT CHILDREN OF 220\n",
      "PRUNE: 236\n",
      "NO ERROR REDUCTION 236\n",
      "PRUNE: 237\n",
      "PRUNING LEFT CHILDREN OF 237\n",
      "PRUNE: 241\n",
      "NO ERROR REDUCTION 241\n",
      "PRUNE: 242\n",
      "PRUNE: 243\n",
      "PRUNE: 244\n",
      "PRUNING RIGHT CHILDREN OF 244\n",
      "PRUNE: 245\n",
      "NO ERROR REDUCTION 245\n",
      "PRUNE: 246\n",
      "PRUNE: 247\n"
     ]
    }
   ],
   "source": [
    "newregressor = reduced_error_pruning(regr, 0, testcoords, testset)\n",
    "out = newregressor.predict(testcoords)\n",
    "out.shape = (h, w, 3)\n",
    "out = out.astype(np.uint8)\n",
    "img = Image.fromarray(out, 'RGB')\n",
    "img.save(\"red_prune_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Difference: 0.141300720629\n",
      "New Score: 0.763080636352\n",
      "Old Score: 0.621779915724\n"
     ]
    }
   ],
   "source": [
    "print(\"Score Difference:\", newregressor.score(testcoords, testset) - regr2.score(testcoords, testset))\n",
    "print(\"New Score:\", newregressor.score(testcoords, testset)) \n",
    "print(\"Old Score:\", regr2.score(testcoords, testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Tree, 7 Layers\n",
    "<img src=\"pre-prune_test.png\" style=\"width: 200px;\"/>\n",
    "After Reduced Error Pruning\n",
    "<img src=\"red_prune_test.png\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pruned.pdf'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(newregressor.estimators_[0].tree_, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"pruned\", view=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. \n",
    "What is the decision rule at each split point? Write down the 1-line formula for the split\n",
    "point at the root node for one the trained decision trees inside the forest. Feel free to\n",
    "define any variables you need. <br>\n",
    "\n",
    "I DONT KNOW\n",
    "\n",
    "#### ii. \n",
    "Why does the resulting image look like the way it does? What shape are the patches of\n",
    "color, and how are they arranged? <br>\n",
    "\n",
    "The image looks boxy because the decision tree splits the values by discrete thresholds.\n",
    "The patches of color are rectangular. They are arranged around the randomly sampled training set of 5000 points.\n",
    "\n",
    "#### iii. \n",
    "Straightforward: How many patches of color may be in the resulting image if the forest\n",
    "contains a single decision tree? Define any variables you need. <br>\n",
    "\n",
    "There may be up to |x| patches of color, where x is the training set.\n",
    "\n",
    "#### iv. \n",
    "Tricky: How many patches of color might be in the resulting image if the forest contains\n",
    "n decision trees? Define any variables you need.\n",
    "\n",
    "The color of a specific pixel is decided by majority vote of the trees in the forest.\n",
    "Given that there are n trees and each tree was trained on a different subset y_n of the sample set, x. \n",
    "There can only be |y_n|*|n| patches of color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
